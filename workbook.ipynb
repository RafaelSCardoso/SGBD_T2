{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "------------------------ HandBook ------------------------\n",
    "#     \tLegenda do resumo\n",
    "# #!# \t= Atribuição ao X\n",
    "# #*# \t= Ação manual necessária\n",
    "# ###!\t= Observações das escolhas no passo\n",
    "# #!\t= Observação para a execução do passo\n",
    "\n",
    "## 1. Importar bibliotecas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#*# 2. Importar dataset\n",
    "#! com pasta 'database/file.csv'\n",
    "file = '.csv'\t\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "## 3. Analise exploratória de dados\n",
    "df.info()\n",
    "df.head()\n",
    "\n",
    "#*# 3.1. Agrupando atributos (facilita a vida)\n",
    "atributos_X \t\t = [] # preenchido no passo 5.5\n",
    "atributos_preditivos = [] # preenchido no passo 4\n",
    "atributo_alvo\t\t = ''\n",
    "atributos    \t\t = []\n",
    "atributos_numericos\t = [] \n",
    "atributos_binarios\t = []\n",
    "atributos_nominais\t = []\n",
    "atributos_enum\t\t = []\n",
    "\n",
    "## 4. Resolvendo valores ausentes\n",
    "atrb_na = []\n",
    "###! Remove linha nula\n",
    "#df_treino.dropna(subset=atrb_na)\n",
    "###! Remove coluna nula\n",
    "#df_treino.drop(atrib_na, axis=1)\n",
    "###! Procura o valor para preencher linhas com valor nulo\n",
    "#! strategy : string, default='mean'\n",
    "#!    - If \"mean\", then replace missing values using the mean along\n",
    "#!      each column. Can only be used with numeric data.\n",
    "#!\n",
    "#!    - If \"median\", then replace missing values using the median along\n",
    "#!      each column. Can only be used with numeric data.\n",
    "#!\tUse when the values are smoothly distributed\n",
    "#!\n",
    "#!    - If \"most_frequent\", then replace missing using the most frequent\n",
    "#!      value along each column. Can be used with strings or numeric data.\n",
    "#!\n",
    "#!    - If \"constant\", then replace missing values with fill_value. Can be\n",
    "#!      used with strings or numeric data.\n",
    "#estrategia\t  = 'mean'\n",
    "#imputer = SimpleImputer(strategy='estrategia')\n",
    "#novos_valores = imputer.fit_transform(df_treino[atrb_na])\n",
    "\n",
    "## 4.1. Calculando as correlações entre os atributos\n",
    "atributos_preditivos = atributos_numericos\n",
    "atributos_preditivos = np.append(atributos_preditivos, atributos_enum)\n",
    "corr = np.corrcoef(df[atributos_preditivos],rowvar=False)\n",
    "dfcorr = pd.DataFrame(corr,index=atributos_preditivos,columns=atributos_preditivos)\n",
    "dfcorr.to_csv('correlmat.csv',sep=';',decimal=',')\n",
    "\n",
    "#*# 4.2. Listando atributos desnecessários\n",
    "#! Atributo com valor muito próximos de 1 do passo acima.\n",
    "#! + Atributos irrelevantes para o aprendizado\n",
    "atributos_desnecessarios = []\n",
    "\n",
    "## 5. Pré-processamento\n",
    "df_treino, df_teste = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "## 5.1. Separando o atributo alvo dos preditivos\n",
    "df_treino_labels = df_treino[atributo_alvo].copy()\n",
    "df_treino        = df_treino.drop(columns=atributo_alvo)\n",
    "\n",
    "## 5.2. (+> 4.1) Removendo atributos desnecessários\n",
    "df_treino = df_treino.drop (columns=atributos_desnecessarios)\n",
    "df_teste  = df_teste.drop  (columns=atributos_desnecessarios)\n",
    "\n",
    "#*# Resolvendo valores ausentes\n",
    "#! Antecipado ao passo 4 para poder exportar Pearson\n",
    "\n",
    "## 5.3. Ajustando a escala dos atributos numéricos quantitativos\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_treino[atributos_numericos])\n",
    "\n",
    "#!# 5.4. Populando o X_treino com colunas numericas\n",
    "X = scaler.transform(df_treino[atributos_numericos])\n",
    "atributos_X = atributos_numericos\n",
    "\n",
    "#!# 5.5. Populando o X_treino com colunas binárias\n",
    "X = np.concatenate((X, df_treino[atributos_binarios]),axis=1)\n",
    "atributos_X = np.append(atributos_X, atributos_binarios)\n",
    "\n",
    "#!# 5.6. Binarizando atributos categóricos\n",
    "for atrb_name in atributos_enum:\n",
    "\t# binarizando a coluna de nome atrb_name\n",
    "\tlb = LabelBinarizer()\n",
    "\tdados = lb.fit_transform(df_treino[atrb_name].values)\n",
    "    \n",
    "\t# acrescentando a matriz com as novas colunas na matriz X\n",
    "\tX = np.concatenate((X, dados),axis=1)\n",
    "    \n",
    "\t# criando nomes para as novas colunas no seguinte formato: nome_do_atributo=valor_do_atributo\n",
    "\tnomes_novos_atributos = []\n",
    "\tfor class_name in lb.classes_:\n",
    "\t\tnomes_novos_atributos = np.append(nomes_novos_atributos,atrb_name+'='+str(class_name))\n",
    "        \n",
    "\t# acrescentando os nomes das novas colunas na lista completa do dataset\n",
    "\tatributos_X = np.append(atributos_X, nomes_novos_atributos)\n",
    "    \n",
    "\t# Debug da transformação de num para enum\n",
    "\t# print('Nome do atributo categórico: ',atrb_name)\n",
    "\t# print('Classes aprendidas: ',lb.classes_)\n",
    "\t# print('Nomes dos novos atributos: ',nomes_novos_atributos)\n",
    "\t# print(\"Primeiras 5 linhas dos dados: \")\n",
    "\t# print(dados[0:5,])\n",
    "\t# print()\n",
    "\n",
    "## 6. Visualização do resultado do pré-processamento\n",
    "df_treino_preproc = pd.DataFrame(X, columns=atributos_X)\n",
    "df_treino_preproc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Importar bibliotecas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*# 2. Importar dataset\n",
    "#! com pasta 'database/file.csv'\n",
    "file = 'Dataset/fertility_Diagnosis.csv'\n",
    "df = pd.read_csv(file)\n",
    "dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Season                 100 non-null    float64\n",
      " 1   Age(18-36)             100 non-null    float64\n",
      " 2   Childish-desease       100 non-null    int64  \n",
      " 3   Trauma                 100 non-null    int64  \n",
      " 4   Surgical-Intervation   100 non-null    int64  \n",
      " 5   Hight-fever-Last-Year  100 non-null    int64  \n",
      " 6   alchohol-consuption    100 non-null    float64\n",
      " 7   smoking-habit          100 non-null    int64  \n",
      " 8   hours-spend-sitting    100 non-null    float64\n",
      " 9   diagnosis              100 non-null    object \n",
      "dtypes: float64(4), int64(5), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Age(18-36)</th>\n",
       "      <th>Childish-desease</th>\n",
       "      <th>Trauma</th>\n",
       "      <th>Surgical-Intervation</th>\n",
       "      <th>Hight-fever-Last-Year</th>\n",
       "      <th>alchohol-consuption</th>\n",
       "      <th>smoking-habit</th>\n",
       "      <th>hours-spend-sitting</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Age(18-36)  Childish-desease  Trauma  Surgical-Intervation  \\\n",
       "0   -0.33        0.69                 0       1                     1   \n",
       "1   -0.33        0.94                 1       0                     1   \n",
       "2   -0.33        0.50                 1       0                     0   \n",
       "3   -0.33        0.75                 0       1                     1   \n",
       "4   -0.33        0.67                 1       1                     0   \n",
       "\n",
       "   Hight-fever-Last-Year  alchohol-consuption  smoking-habit  \\\n",
       "0                      0                  0.8              0   \n",
       "1                      0                  0.8              1   \n",
       "2                      0                  1.0             -1   \n",
       "3                      0                  1.0             -1   \n",
       "4                      0                  0.8             -1   \n",
       "\n",
       "   hours-spend-sitting diagnosis  \n",
       "0                 0.88         N  \n",
       "1                 0.31         O  \n",
       "2                 0.50         N  \n",
       "3                 0.38         N  \n",
       "4                 0.50         O  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3. Analise exploratória de dados\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*# 3.1. Agrupando atributos (facilita a vida)\n",
    "atributos_X          = [] # Preenchido no passo 5.5\n",
    "atributos_preditivos = [] # Usado no passo 4\n",
    "\n",
    "#Definindo os atributos\n",
    "atributo_alvo        = 'diagnosis'\n",
    "atributos_numericos  = ['Age(18-36)', 'hours-spend-sitting']\n",
    "atributos_binarios   = ['diagnosis']\n",
    "atributos_nominais   = ['Season', 'Childish-desease', 'Surgical-Intervation', 'Hight-fever-Last-Year', 'alchohol-consuption', 'smoking-habit']\n",
    "atributos_enum       = ['diagnosis']\n",
    "\n",
    "atributos_desnecessarios = ['Season']\n",
    "\n",
    "#Removendo o atributo alvo das variáveis de pesquisa\n",
    "atributos_numericos  = [ x for x in atributos_numericos if x is not atributo_alvo ]\n",
    "atributos_binarios   = [ x for x in atributos_binarios if x is not atributo_alvo ]\n",
    "atributos_nominais   = [ x for x in atributos_nominais if x is not atributo_alvo ]\n",
    "atributos_enum       = [ x for x in atributos_enum if x is not atributo_alvo ]\n",
    "# Reunindo atributos\n",
    "atributos            = atributos_numericos\n",
    "atributos            = np.append(atributos, atributos_binarios)\n",
    "atributos            = np.append(atributos, atributos_nominais)\n",
    "atributos            = np.append(atributos, atributos_enum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 4. Resolvendo valores ausentes\n",
    "# atrb_na = ['']2\n",
    "###! Remove linha nula\n",
    "# df = df.dropna(subset=atrb_na)\n",
    "###! Remove coluna nula\n",
    "#df = df.drop(atrib_na, axis=1)\n",
    "###! Procura o valor para preencher linhas com valor nulo\n",
    "#! strategy : string, default='mean'\n",
    "#!    - If \"mean\", then replace missing values using the mean along\n",
    "#!      each column. Can only be used with numeric data.\n",
    "#!\n",
    "#!    - If \"median\", then replace missing values using the median along\n",
    "#!      each column. Can only be used with numeric data.\n",
    "#!\tUse when the values are smoothly distributed\n",
    "#!\n",
    "#!    - If \"most_frequent\", then replace missing using the most frequent\n",
    "#!      value along each column. Can be used with strings or numeric data.\n",
    "#!\n",
    "#!    - If \"constant\", then replace missing values with fill_value. Can be\n",
    "#!      used with strings or numeric data.\n",
    "#estrategia\t  = 'mean'\n",
    "#imputer = SimpleImputer(strategy=estrategia)\n",
    "#novos_valores = imputer.fit_transform(df_treino[atrb_na])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de atributos preditivos:  2 .\n",
      "Lista dos atributos preditivos: ['Age(18-36)' 'hours-spend-sitting']\n"
     ]
    }
   ],
   "source": [
    "## 4.1. Calculando as correlações entre os atributos\n",
    "# Prepara os atributos não String\n",
    "atributos_preditivos = atributos_numericos\n",
    "atributos_preditivos = np.append(atributos_preditivos, atributos_enum)\n",
    "\n",
    "print (\n",
    "    'Quantidade de atributos preditivos: ',\n",
    "        atributos_preditivos.size,\n",
    "    '.\\nLista dos atributos preditivos:',\n",
    "        atributos_preditivos)\n",
    "\n",
    "# Correlação de Pearson\n",
    "corr = np.corrcoef(df[atributos_preditivos],rowvar=False)\n",
    "\n",
    "# Tabularização das informações\n",
    "dfcorr = pd.DataFrame(corr,index=atributos_preditivos,columns=atributos_preditivos)\n",
    "\n",
    "# Exporta para csv\n",
    "dfcorr.to_csv('correlmat.csv',sep=';',decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## +STEP Comparando correlação (revalidando Peason)\n",
    "# pd.plotting.scatter_matrix(df[atributos],figsize=(20, 20))\n",
    "# plt.show()\n",
    "\n",
    "# df.plot(x='', y='', kind='hist')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*# 4.2. Listando atributos desnecessários\n",
    "#! Atributo com valor muito próximos de 1 do passo acima.\n",
    "#! + Atributos irrelevantes para o aprendizado\n",
    "\n",
    "# Variável correlacionado com cylinders (Peason 0,95)\n",
    "# atributos_desnecessarios = ['']\n",
    "\n",
    "# Removendo a variável desnecessária dos atributos\n",
    "for atrb_name in atributos_desnecessarios:\n",
    "    atributos_numericos  = [ x for x in atributos_numericos if x is not atrb_name ]\n",
    "    atributos_binarios   = [ x for x in atributos_binarios if x is not atrb_name ]\n",
    "    atributos_nominais   = [ x for x in atributos_nominais if x is not atrb_name ]\n",
    "    atributos_enum       = [ x for x in atributos_enum if x is not atrb_name ]\n",
    "    \n",
    "atributos = atributos_numericos\n",
    "atributos = np.append(atributos, atributos_binarios)\n",
    "atributos = np.append(atributos, atributos_nominais)\n",
    "atributos = np.append(atributos, atributos_enum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Pré-processamento\n",
    "df_treino, df_teste = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5.1. Separando o atributo alvo dos preditivos\n",
    "df_treino_labels = df_treino[atributo_alvo].copy()\n",
    "df_treino        = df_treino.drop(columns=atributo_alvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5.2. (+> 4.1) Removendo atributos desnecessários\n",
    "df_treino = df_treino.drop (columns=atributos_desnecessarios)\n",
    "df_teste  = df_teste.drop  (columns=atributos_desnecessarios)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#*# Resolvendo valores ausentes\n",
    "#! Antecipado ao passo 4 para poder exportar o Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 5.3. Ajustando a escala dos atributos numéricos quantitativos\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_treino[atributos_numericos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!# 5.4. Populando o X_treino com colunas numericas\n",
    "X = scaler.transform(df_treino[atributos_numericos])\n",
    "atributos_X = atributos_numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!# 5.5. Populando o X_treino com colunas binárias\n",
    "X = np.concatenate((X, df_treino[atributos_binarios]),axis=1)\n",
    "atributos_X = np.append(atributos_X, atributos_binarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!# 5.6. Binarizando atributos categóricos\n",
    "for atrb_name in atributos_enum:\n",
    "    # binarizando a coluna de nome atrb_name\n",
    "    lb = LabelBinarizer()\n",
    "    dados = lb.fit_transform(df_treino[atrb_name].values)\n",
    "    \n",
    "    # acrescentando a matriz com as novas colunas na matriz X\n",
    "    X = np.concatenate((X, dados),axis=1)\n",
    "    \n",
    "    # criando nomes para as novas colunas no seguinte formato: nome_do_atributo=valor_do_atributo\n",
    "    nomes_novos_atributos = []\n",
    "    for class_name in lb.classes_:\n",
    "        nomes_novos_atributos = np.append(nomes_novos_atributos,atrb_name+'='+str(class_name))\n",
    "        \n",
    "    # acrescentando os nomes das novas colunas na lista completa do dataset\n",
    "    atributos_X = np.append(atributos_X, nomes_novos_atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.73457576, -1.16801178],\n",
       "       [ 1.31731183, -0.50648298]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age(18-36)</th>\n",
       "      <th>hours-spend-sitting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.734576</td>\n",
       "      <td>-1.168012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.317312</td>\n",
       "      <td>-0.506483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004104</td>\n",
       "      <td>-0.120591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.734576</td>\n",
       "      <td>0.540938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.391180</td>\n",
       "      <td>0.540938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age(18-36)  hours-spend-sitting\n",
       "0   -0.734576            -1.168012\n",
       "1    1.317312            -0.506483\n",
       "2    0.004104            -0.120591\n",
       "3   -0.734576             0.540938\n",
       "4   -1.391180             0.540938"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 6. Visualização do resultado do pré-processamento\n",
    "df_treino_preproc = pd.DataFrame(X, columns=atributos_X)\n",
    "df_treino_preproc.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
